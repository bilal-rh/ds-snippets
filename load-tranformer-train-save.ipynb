{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79433983-8aa7-42c7-ae1e-c11b9b7473ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the necessary libraries\n",
    "!pip install transformers datasets torch evaluate accelerate boto3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc99eec1-3983-4938-a565-50dadb7b6da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the necessary functions and APIs\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38140de4-749b-46bf-b514-a39e8e83bc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# disable tokenizers parallelism warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# load a portion of the AG News dataset (500 examples)\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "small_dataset = dataset[\"train\"].shuffle(seed=42).select(range(500))  \n",
    "\n",
    "# load the model (prajjwal1/bert-tiny), tokenizer, and pre-trained model\n",
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "# define the function to tokenize text examples using the loaded tokenizer\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# apply the tokenize_function to the small_dataset using map function\n",
    "tokenized_datasets = small_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# specify the training arguments, i.e. output directory, evaluation strategy, learning rate, batch size, number of epochs, weight decay, and load the best model at the end\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,  \n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# load the accuracy metric from the evaluate library\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# compute evaluate metrics by taking the eval predictions (logits and labels) and calculate the accuracy using the loaded metric\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# set up the training process by taking the model, training arguments, train and eval datasets, tokenizer and the compute_metrics function\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets,  \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# start the training process using the configured trainer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239074d2-e4b2-4483-b4de-d9a524446967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_841/210600936.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 02:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.357099</td>\n",
       "      <td>0.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.332813</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.324350</td>\n",
       "      <td>0.532000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=1.3565202339616402, metrics={'train_runtime': 132.9307, 'train_samples_per_second': 11.284, 'train_steps_per_second': 1.422, 'total_flos': 297141746496.0, 'train_loss': 1.3565202339616402, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4628bc5-74fd-4dc2-8c9b-c4a12effce34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model and tokenizer into model folder\n",
    "model_save_dir = \"./model\"\n",
    "tokenizer.save_pretrained(model_save_dir)\n",
    "model.save_pretrained(model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de478165-39e0-4bd0-91d0-4a152ec0b2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload the saved model to s3 bucket\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'models-bucket' # please change this with your own bucket name\n",
    "model_save_path = 'tiny/'\n",
    "\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        endpoint_url=endpoint_url,\n",
    "        region_name=region_name,\n",
    ")\n",
    "\n",
    "\n",
    "bucket_name = 'models-bucket' # please change this with your own bucket name\n",
    "model_save_path = 'tiny/'\n",
    "\n",
    "for file_name in os.listdir(model_save_dir):\n",
    "    s3_client.upload_file(\n",
    "        os.path.join(model_save_dir, file_name),\n",
    "        bucket_name,\n",
    "        model_save_path + file_name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8702997-d9a8-42b9-a48a-22e3253f41d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print 'Finshed...'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
